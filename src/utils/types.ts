import { 
    OpenAIConfig as LLMAPIConfig, 
    ModelConfig as LLMAPIModelConfig,
    OpenAIChatApi
} from 'llm-api'

import { 
    Options as SequelizeOptions,
    Sequelize
} from 'sequelize';

/**
 * The arguments for initializing the LLMToSQL class.
 * @param llmApi the LLM API instance to use (Either this or llmApiConfig and llmApiModelConfig must be provided)
 * @param llmApiConfig the LLM API configuration to use (Either this or llmApi must be provided)
 * @param llmApiModelConfig the LLM API model configuration to use (Either this or llmApi must be provided)
 * @param sequelize the ORM instance to use (Either this or sequelizeOptions must be provided)
 * @param sequelizeOptions the ORM configuration to use (Either this or sequelize must be provided)
 * @param sqlInfo the SQL schema information to use (Either this or sequelize must be provided)
 */
export interface LLMToSQLArgs {
    llmApi?: OpenAIChatApi;
    llmApiConfig?: LLMAPIConfig;
    llmApiModelConfig?: LLMAPIModelConfig;
    sequelize?: Sequelize;
    sequelizeOptions?: SequelizeOptions;
    sqlInfo?: string;
};

/**
 * This is the type of the data that will be passed to the function.    
 */
export interface LLMToSQLResponse {
    /**
     * The SQL query generated by the LLM model.
     */
    sqlQuery: string;
    /**
     * If the SQL query was executed, the results of the query by sequelize.
     */
    results?: any[];
}

/**
 * This is the information needed to init a llm-api instance.
 */
export type { LLMAPIConfig };

/**
 * This is the information needed to init a llm-api instance.
 */
export type { LLMAPIModelConfig };

/**
 * This is the information needed to init a sequelize instance.
 */
export type { SequelizeOptions };
